{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f6ef69",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(90deg, #bbd2c5, #536976); padding: 20px; border-radius: 15px; color: #222;\">\n",
    "\n",
    "<h1 style=\"margin-bottom: 15px;\">Groupe : <span>Iheb Alimi - Riadh Ibrahim</span></h1>\n",
    "<h3 style=\"margin-top: 0;\">Mati√®re : <span style=\"color: #43a047;\">Analyse Vid√©o</span></h3>\n",
    "<h3 style=\"margin-top: 0;\">TP 2 : <span style=\"color: #d32f2f;\">Optical Flow estimation and visualization</span></h3>\n",
    "<h3 style=\"margin-top: 0;\">Github Repo : https://github.com/alimiheb/VIDEO-ANALYSIS-LABS </h3>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16f5a2",
   "metadata": {},
   "source": [
    "Dans ce TP, nous allons tester et comparer trois algorithmes d'optical flow :\n",
    "- **Lucas-Kanade** (m√©thode sparse)\n",
    "- **Farneback** (m√©thode dense)\n",
    "- **RLOF** (Robust Local Optical Flow - m√©thode dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69ada1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installation des packages n√©cessaires\n",
    "%pip install opencv-contrib-python matplotlib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ed763e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biblioth√®ques import√©es avec succ√®s!\n",
      "OpenCV version: 4.12.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"Biblioth√®ques import√©es avec succ√®s!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c4e849",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(90deg, #bbd2c5, #536976); padding: 20px; border-radius: 15px; color: #222;\">\n",
    "\n",
    "## üé¨ Chargement de la Vid√©o du Lab1\n",
    "\n",
    "Nous utilisons la vid√©o du Lab1 pour l'analyse d'optical flow.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7922f2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vid√©o trouv√©e: ../Lab1/my_vid.mp4\n",
      "üìπ Propri√©t√©s de la vid√©o:\n",
      "   - Nombre de frames: 282\n",
      "   - FPS: 29.97\n",
      "   - Dur√©e: 9.41 secondes\n",
      "üìπ Propri√©t√©s de la vid√©o:\n",
      "   - Nombre de frames: 282\n",
      "   - FPS: 29.97\n",
      "   - Dur√©e: 9.41 secondes\n"
     ]
    }
   ],
   "source": [
    "# Chargement de la vid√©o du Lab1\n",
    "video_path = '../Lab1/my_vid.mp4'\n",
    "\n",
    "# V√©rification de l'existence du fichier\n",
    "if not os.path.exists(video_path):\n",
    "    print(f\"‚ùå Vid√©o non trouv√©e √†: {video_path}\")\n",
    "    print(\"Veuillez ajuster le chemin vers votre vid√©o du Lab1\")\n",
    "else:\n",
    "    print(f\"‚úÖ Vid√©o trouv√©e: {video_path}\")\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "                            \n",
    "# Informations sur la vid√©o\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = frame_count / fps if fps > 0 else 0\n",
    "    \n",
    "print(f\"üìπ Propri√©t√©s de la vid√©o:\")\n",
    "print(f\"   - Nombre de frames: {frame_count}\")\n",
    "print(f\"   - FPS: {fps:.2f}\")\n",
    "print(f\"   - Dur√©e: {duration:.2f} secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566f2ddf",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(90deg, #bbd2c5, #536976); padding: 20px; border-radius: 15px; color: #222;\">\n",
    "\n",
    "## 1Ô∏è‚É£ M√©thode Sparse : Lucas-Kanade Optical Flow ( trait√©e durant le cours)\n",
    "\n",
    "### üìö Explication Th√©orique\n",
    "\n",
    "**Lucas-Kanade** est une m√©thode **sparse** d'estimation de l'optical flow qui :\n",
    "\n",
    "- **Principe** : Suit des points caract√©ristiques s√©lectionn√©s entre deux frames\n",
    "- **Hypoth√®ses** : \n",
    "  - Constance de la luminosit√© : `I(x,y,t) = I(x+dx, y+dy, t+dt)`\n",
    "  - D√©placements petits entre frames cons√©cutives\n",
    "  - Mouvement coh√©rent dans un voisinage local\n",
    "- **Avantages** : Rapide, robuste pour petits mouvements, facile √† interpr√©ter\n",
    "- **Inconv√©nients** : Ne donne pas d'information sur tous les pixels, sensible aux gros d√©placements\n",
    "\n",
    "### üî¨ Impl√©mentation et Test\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6ed4f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lucas_kanade_method(video_path):\n",
    "    # Read the video \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    " \n",
    "    # Parameters for ShiTomasi corner detection\n",
    "    feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    " \n",
    "    # Parameters for Lucas Kanade optical flow\n",
    "    lk_params = dict(\n",
    "        winSize=(15, 15),\n",
    "        maxLevel=2,\n",
    "        criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
    "    )\n",
    " \n",
    "    # Create random colors\n",
    "    color = np.random.randint(0, 255, (100, 3))\n",
    " \n",
    "    # Take first frame and find corners in it\n",
    "    ret, old_frame = cap.read()\n",
    "    old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    " \n",
    "    # Create a mask image for drawing purposes\n",
    "    mask = np.zeros_like(old_frame)\n",
    "\n",
    "    return cap, old_gray, p0, mask, color, lk_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fa6caf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'old_gray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m frame_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate Optical Flow\u001b[39;00m\n\u001b[0;32m      9\u001b[0m p1, st, err \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcOpticalFlowPyrLK(\n\u001b[1;32m---> 10\u001b[0m     old_gray, frame_gray, p0, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlk_params\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Select good points\u001b[39;00m\n\u001b[0;32m     13\u001b[0m good_new \u001b[38;5;241m=\u001b[39m p1[st \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'old_gray' is not defined"
     ]
    }
   ],
   "source": [
    "#video_path = '../Lab1/my_vid.mp4'\n",
    "cap, old_gray, p0, mask, color, lk_params = lucas_kanade_method(video_path)\n",
    "\n",
    "while True:\n",
    "    # Read new frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate Optical Flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
    "        old_gray, frame_gray, p0, None, **lk_params\n",
    "    )\n",
    "    # Select good points\n",
    "    good_new = p1[st == 1]\n",
    "    good_old = p0[st == 1]\n",
    "\n",
    "    # Draw the tracks\n",
    "    for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a, b = new.ravel()\n",
    "        c, d = old.ravel()\n",
    "        mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2)\n",
    "        frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
    "\n",
    "    # Display the demo\n",
    "    img = cv2.add(frame, mask)\n",
    "    cv2.imshow(\"LK Result\", img)\n",
    "    k = cv2.waitKey(25) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f9429d",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(90deg, #bbd2c5, #536976); padding: 22px; border-radius: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif;\">\n",
    "\n",
    "  <h2 style=\"margin-top:0;\">2Ô∏è‚É£ M√©thode Dense : Farneback Optical Flow</h2>\n",
    "  <h4 style=\"margin-bottom:12px;\">(non trait√©e durant le cours)</h4>\n",
    "\n",
    "  <h3 style=\"margin-top:4px;color:#274472;\">üìö Explication Th√©orique</h3>\n",
    "  <div style=\"line-height:1.7;\">\n",
    "    <b>Farneback</b> est une m√©thode <b>dense</b> d‚Äôestimation du flux optique qui¬†:\n",
    "    <ul style=\"margin-bottom:12px;\">\n",
    "      <li><span style=\"color:#293462;\"> <b>Principe :</b>  Calcule le mouvement pour chaque pixel de l‚Äôimage, ce qui signifie que le r√©sultat est un champ de vecteurs dense couvrant enti√®rement la sc√®ne.</span></li>\n",
    "      <li><span style=\"color:#293462;\"> <b>Approche :</b>  Utilise une <b>approximation polynomiale</b> locale (de second ordre, quadratique) pour mod√©liser l‚Äôintensit√© autour de chaque pixel dans deux images cons√©cutives, puis observe comment ces polyn√¥mes changent lors des d√©placements d‚Äôobjet.</span></li>\n",
    "      <li><span style=\"color:#293462;\"> <b>Pyramide d‚Äôimages :</b>  La m√©thode travaille sur plusieurs √©chelles (pyramide), ce qui am√©liore la robustesse sur les mouvements rapides et globaux.</span></li>\n",
    "      <li><span style=\"color:#293462;\"> <b>√âquation :</b>  √Ä chaque voisinage, on approxime l‚Äôintensit√© I(x) par un polyn√¥me quadratique. On cherche alors la translation qui aligne au mieux ces approximations en analysant les diff√©rences polynomiales entre les deux images.</span></li>\n",
    "    </ul>\n",
    "\n",
    "  <span style=\"font-size:1.09em;\">\n",
    "      <b>Avantages :</b>\n",
    "      <ul>\n",
    "        <li>Produit un champ de mouvement <b>complet</b> (chaque pixel a son vecteur)</li>\n",
    "        <li>Tr√®s utile pour les analyses fines, les mouvements globaux ou d√©formables</li>\n",
    "        <li><span style=\"color:#333;\">Robuste</span> aux variations d‚Äôillumination dues √† la moyenne locale</li>\n",
    "      </ul>\n",
    "      <b>Inconv√©nients :</b>\n",
    "      <ul>\n",
    "        <li><span style=\"color:#400e32;\">Plus lent</span> que les m√©thodes sparse comme Lucas-Kanade</li>\n",
    "        <li>Peut g√©n√©rer du bruit dans les zones homog√®nes (peu de texture)</li>\n",
    "      </ul>\n",
    "    </span>\n",
    "  </div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f6662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_optical_flow(method, video_path, params=[], to_gray=False):\n",
    "    # Read the video and first frame\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    ret, old_frame = cap.read()\n",
    " \n",
    "    # crate HSV & make Value a constant\n",
    "    hsv = np.zeros_like(old_frame)\n",
    "    hsv[..., 1] = 255\n",
    " \n",
    "    # Preprocessing for exact method\n",
    "    if to_gray:\n",
    "        old_frame = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return cap, old_frame, hsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776cab18",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(90deg, #bbd2c5, #536976); padding: 22px; border-radius: 15px; color: #222; font-family: 'Segoe UI', Arial, sans-serif;\">\n",
    "\n",
    "  <h2 style=\"margin-top:0;\">3Ô∏è‚É£ M√©thode Dense : RLOF (Robust Local Optical Flow)</h2>\n",
    "  <h4 style=\"margin-bottom:12px;\">(non trait√©e durant le cours)</h4>\n",
    "\n",
    "  <h3 style=\"margin-top:4px;color:#274472;\">üìö Explication Th√©orique</h3>\n",
    "  <div style=\"line-height:1.7;\">\n",
    "    <b>RLOF</b> (Robust Local Optical Flow) est une m√©thode <b>dense</b> d‚Äôestimation du flux optique publi√©e en 2016, qui am√©liore la robustesse dans des conditions r√©elles :\n",
    "    <ul style=\"margin-bottom:12px;\">\n",
    "      <li><span style=\"color:#293462;\"> <b>Principe :</b> M√©thode robuste combinant informations locales et globales pour une meilleure coh√©rence du mouvement.</span></li>\n",
    "      <li><span style=\"color:#293462;\"> <b>Mod√®le d‚Äôillumination :</b> Prend explicitement en compte les variations d‚Äôillumination (ombres, reflets, m√©t√©o, etc.), contrairement √† l‚Äôhypoth√®se de constance d‚Äôintensit√© classique.</span></li>\n",
    "      <li><span style=\"color:#293462;\"> <b>Algorithme :</b> Repose sur une estimation initiale locale, puis sur l‚Äôoptimisation d‚Äôune fonction de co√ªt pond√©r√©e par fiabilit√©, it√©r√©e jusqu‚Äô√† convergence.</span></li>\n",
    "      <li><span style=\"color:#293462;\"> <b>Robustesse :</b> R√©sistant aux variations de lumi√®re, occlusions, bruit et objets en mouvement complexe.</span></li>\n",
    "    </ul>\n",
    "    <span style=\"font-size:1.09em;\">\n",
    "    <b>Avantages :</b>\n",
    "      <ul>\n",
    "        <li>Excellente robustesse aux conditions complexes et aux discontinuit√©s</li>\n",
    "        <li>Bonne gestion des contours et occlusions</li>\n",
    "        <li>Haute pr√©cision sur les objets mouvants</li>\n",
    "      </ul>\n",
    "      <b>Inconv√©nients :</b>\n",
    "      <ul>\n",
    "        <li>Plus co√ªteux en calcul</li>\n",
    "      </ul>\n",
    "    </span>\n",
    "  </div>\n",
    "\n",
    "  <h3 style=\"margin-top:23px; color:#274472;\">üî¨ Impl√©mentation et Test</h3>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cabf542e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2.optflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#%pip install opencv-contrib-python\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptflow\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize RLOF\u001b[39;00m\n\u001b[0;32m      6\u001b[0m method \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39moptflow\u001b[38;5;241m.\u001b[39mcalcOpticalFlowDenseRLOF\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2.optflow'"
     ]
    }
   ],
   "source": [
    "#%pip install opencv-contrib-python\n",
    "\n",
    "import cv2.optflow\n",
    "\n",
    "# Initialize RLOF\n",
    "method = cv2.optflow.calcOpticalFlowDenseRLOF\n",
    "to_gray = True\n",
    "\n",
    "cap, old_frame, hsv = dense_optical_flow(method, video_path, to_gray=to_gray)\n",
    "\n",
    "while True:\n",
    "    ret, new_frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_copy = new_frame.copy()\n",
    " \n",
    "    if to_gray:\n",
    "        new_frame = cv2.cvtColor(new_frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Calculate RLOF Optical Flow\n",
    "    flow = method(old_frame, new_frame, None)\n",
    " \n",
    "    # Encoding\n",
    "    mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    hsv[..., 0] = ang * 180 / np.pi / 2\n",
    "    hsv[..., 2] = cv2.normalize(mag, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv2.imshow(\"frame\", frame_copy)\n",
    "    cv2.imshow(\"optical flow\", bgr)\n",
    "    k = cv2.waitKey(25) & 0xFF\n",
    "    if k == 27:  # ESC key\n",
    "        break\n",
    " \n",
    "    old_frame = new_frame\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba1ada3",
   "metadata": {},
   "source": [
    "**R√©f√©rence** : [Optical Flow in OpenCV - LearnOpenCV](https://learnopencv.com/optical-flow-in-opencv/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atelier_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
